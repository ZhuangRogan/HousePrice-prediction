{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn as skl\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-27T05:55:10.839894Z","iopub.execute_input":"2021-11-27T05:55:10.841274Z","iopub.status.idle":"2021-11-27T05:55:11.903458Z","shell.execute_reply.started":"2021-11-27T05:55:10.841121Z","shell.execute_reply":"2021-11-27T05:55:11.902291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = \"../input/house-prices-advanced-regression-techniques/train.csv\"\ntest_path = \"../input/house-prices-advanced-regression-techniques/test.csv\"\n\ndf_train = pd.read_csv(train_path, index_col=0)\ndf_test = pd.read_csv(test_path)\nprint(df_train.shape)\nprint(df_test.shape) #少了y\ndf_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:11.905758Z","iopub.execute_input":"2021-11-27T05:55:11.906148Z","iopub.status.idle":"2021-11-27T05:55:12.013255Z","shell.execute_reply.started":"2021-11-27T05:55:11.906101Z","shell.execute_reply":"2021-11-27T05:55:12.012295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ID = df_test['Id']\ndf_test.drop(\"Id\", axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.014956Z","iopub.execute_input":"2021-11-27T05:55:12.015288Z","iopub.status.idle":"2021-11-27T05:55:12.025522Z","shell.execute_reply.started":"2021-11-27T05:55:12.015245Z","shell.execute_reply":"2021-11-27T05:55:12.024432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 分析目標","metadata":{}},{"cell_type":"code","source":"def Plot_Scatter(X, y, n_col=5):\n    n_col = 5\n    fig, axs = plt.subplots(int((X.shape[1])/n_col), n_col, sharey='row', figsize=(40,120))\n    axs = axs.ravel()\n    i=0\n    for col in X.columns[0:X.shape[1]-1]:\n        data1 = pd.concat([y, X[col]], axis=1).copy()\n    \n        if data1[col].hasnans:\n            if data1[col].dtype==object:\n                data1[col] = data1[col].fillna(\"None\")\n            else:\n                data1[col] = data1[col].fillna(0)\n        #data1.plot.scatter(x=col, y='SalePrice', ylim=(0,800000));\n        axs[i].scatter(x=data1[col], y=y);\n        axs[i].set_title(col)\n        \n        if data1[col].dtype==object:\n            axs[i].tick_params(rotation=290)\n            #plt.xticks(rotation=-290)\n        else:\n            pass\n            #plt.xticks(rotation=0)\n        i+=1\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.027756Z","iopub.execute_input":"2021-11-27T05:55:12.028458Z","iopub.status.idle":"2021-11-27T05:55:12.041892Z","shell.execute_reply.started":"2021-11-27T05:55:12.028422Z","shell.execute_reply":"2021-11-27T05:55:12.041118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Data_Analysing(df, df_y, verbose=0):  #verbose= 全不輸出->0  只輸出數據->1 輸出基本圖->2 輸出次要圖->3 全部輸出->4\n    from sklearn import preprocessing\n    print(\"樣本數:\", df.shape[0])\n    print(\"特徵數:\", df.shape[1])\n    print('\\n')\n    print(\"目標統計\")\n    if verbose>0:\n        pass\n        #print(df_y.describe())\n        \n    if verbose>1:\n        sns.histplot(df_y);\n        plt.show()\n        \n    n = 10\n    y_scaled = skl.preprocessing.StandardScaler().fit_transform(df_y)\n    low_range = y_scaled[y_scaled[:,0].argsort()][:n]\n    high_range= y_scaled[y_scaled[:,0].argsort()][-n:]\n\n    print(\"y偏度: %f\" % df_y.skew())\n    print(\"y峰度: %f\" % df_y.kurt())\n    print(\"y極低值範圍分布:\",  low_range.reshape(n))\n    print(\"y極高值範圍分布:\", high_range.reshape(n))\n    \n    print('\\n')\n    \n    if verbose>0:\n        print(\"MI統計\")\n        target = df_y.columns[0]\n        corrmat = df.corr()\n        k = 10 #number of variables for heatmap\n        cols = corrmat.nlargest(k, target)[target].index\n        print(\"MI最大的前{}名:\".format(k), [col for col in cols])  #未完成\n    if verbose>2:\n        f, ax = plt.subplots(figsize=(9, 9))\n        sns.heatmap(corrmat, vmax=.8, square=True);  #全heat map\n        plt.show()\n    if verbose>1:\n        \n        cm = np.corrcoef(df_train[cols].values.T)\n        sns.set(font_scale=1.25)\n        hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values);  #部分heat map\n        plt.show()\n    if verbose>3:\n        sns.set()\n        #cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n        sns.pairplot(df_train[cols], height = 2.5);\n        plt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.043202Z","iopub.execute_input":"2021-11-27T05:55:12.044021Z","iopub.status.idle":"2021-11-27T05:55:12.059Z","shell.execute_reply.started":"2021-11-27T05:55:12.043976Z","shell.execute_reply":"2021-11-27T05:55:12.057978Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data_Analysing(df_train, pd.DataFrame(df_train['SalePrice']), verbose=0)\n#Plot_Scatter(df_train, df_train['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.060731Z","iopub.execute_input":"2021-11-27T05:55:12.061277Z","iopub.status.idle":"2021-11-27T05:55:12.112554Z","shell.execute_reply.started":"2021-11-27T05:55:12.061228Z","shell.execute_reply":"2021-11-27T05:55:12.111464Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"分析完畢! 接著進行數據的處理","metadata":{}},{"cell_type":"markdown","source":"# 數據處理\n附註:\n1. 由於有時間性數據，有餘裕可考慮通膨","metadata":{}},{"cell_type":"code","source":"#deleting sample\noutlier = df_train.sort_values(by = 'GrLivArea', ascending = False)[:2].index\n#outlier.append(df_train.sort_values(by = 'LotFrontage', ascending = False)[:2].index)\n#outlier.append(df_train.sort_values(by = 'LotArea', ascending = False)[:4].index)\nprint(outlier)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.114201Z","iopub.execute_input":"2021-11-27T05:55:12.114618Z","iopub.status.idle":"2021-11-27T05:55:12.123262Z","shell.execute_reply.started":"2021-11-27T05:55:12.114577Z","shell.execute_reply":"2021-11-27T05:55:12.122529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    df_train = df_train.drop(index=df_train.sort_values(by = 'GrLivArea', ascending = False)[:2].index)\n    #df_train = df_train.drop(index=524)\n    print(\"deleted\")\nexcept:\n    print(\"points has been deleted\")","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.124713Z","iopub.execute_input":"2021-11-27T05:55:12.125209Z","iopub.status.idle":"2021-11-27T05:55:12.141723Z","shell.execute_reply.started":"2021-11-27T05:55:12.125177Z","shell.execute_reply":"2021-11-27T05:55:12.140868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"常態性處理  \n這裡以非常精簡的方式測試“SalePrice”。注意兩點：  \n1. 直方圖 - 峰度和偏度。\n2. 常態機率圖 - 數據分佈應緊貼代表常態分佈的對角線。","metadata":{}},{"cell_type":"markdown","source":"'SalePrice'並不常態。有個峰值、正偏度且不遵循常態分佈對角線。\n\n但還沒有亂掉，簡單的數據轉換就可以解決這個問題。在正偏度的情況下，對數轉換通常效果很好。","metadata":{}},{"cell_type":"code","source":"from scipy.stats import norm\nfrom scipy import stats\n\ndf_train_norm = df_train.copy()\ndf_train_norm['SalePrice'] = np.log(df_train['SalePrice'])\n\nsns.displot(df_train_norm['SalePrice'], kde=True);\nfig = plt.figure()\nres = stats.probplot(df_train_norm['SalePrice'], plot=plt)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.143725Z","iopub.execute_input":"2021-11-27T05:55:12.144507Z","iopub.status.idle":"2021-11-27T05:55:12.952589Z","shell.execute_reply.started":"2021-11-27T05:55:12.144454Z","shell.execute_reply":"2021-11-27T05:55:12.951466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"以下進行缺失補值，在此訓練集和測試集一同處理比較方便","metadata":{}},{"cell_type":"code","source":"ntrain = df_train_norm.shape[0]\nntest = df_test.shape[0]\ny_train = df_train_norm.SalePrice.values\ndf = pd.concat((df_train_norm, df_test)).reset_index(drop=True)\ndf.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(df.shape))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.95575Z","iopub.execute_input":"2021-11-27T05:55:12.956081Z","iopub.status.idle":"2021-11-27T05:55:12.986672Z","shell.execute_reply.started":"2021-11-27T05:55:12.956047Z","shell.execute_reply":"2021-11-27T05:55:12.985791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"數據格式:\n有些特徵明明是類別，卻以數值紀錄，要對它做轉換","metadata":{}},{"cell_type":"code","source":"df['MSSubClass'] = df['MSSubClass'].apply(str)\n\n\ndf['OverallCond'] = df['OverallCond'].astype(str)\n\ndf['YrSold'] = df['YrSold'].astype(str)\ndf['MoSold'] = df['MoSold'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:12.987971Z","iopub.execute_input":"2021-11-27T05:55:12.988711Z","iopub.status.idle":"2021-11-27T05:55:13.005013Z","shell.execute_reply.started":"2021-11-27T05:55:12.988666Z","shell.execute_reply":"2021-11-27T05:55:13.004245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"處理缺失值，有幾點需要考慮:\n1. 缺失值有多少?\n2. 缺失值是隨機的? 還是代表某種資訊?\n如何看待這件事很重要，因為缺少的值會讓我們能分析的事變少，而且處理缺失值的手法也不能偏離真相","metadata":{}},{"cell_type":"code","source":"total = df.isnull().sum().sort_values(ascending=False)\nmiss_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, miss_percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20).T","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.006575Z","iopub.execute_input":"2021-11-27T05:55:13.007177Z","iopub.status.idle":"2021-11-27T05:55:13.062253Z","shell.execute_reply.started":"2021-11-27T05:55:13.007122Z","shell.execute_reply":"2021-11-27T05:55:13.061109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"通常，當一種特徵有超過15%遺失時，我們會考慮去掉，假裝它不存在，好讓我們不用煩惱該如何填充。   至於15%以下的，如果有其他Feature可以替代者，也可刪掉(例如Garage系列特徵都可由GarageCars取代)  \n當然我們也可以逐一分析，擬定該如何進行填充。","metadata":{"execution":{"iopub.status.busy":"2021-10-29T08:31:54.268736Z","iopub.execute_input":"2021-10-29T08:31:54.269207Z","iopub.status.idle":"2021-10-29T08:31:54.275435Z","shell.execute_reply.started":"2021-10-29T08:31:54.269163Z","shell.execute_reply":"2021-10-29T08:31:54.274412Z"}}},{"cell_type":"code","source":"#暴力法\ndrop_col = missing_data[missing_data['Total']> 0]\ntry:\n    df_brutal_NA = df.drop(labels=drop_col.index,axis=1, inplace=False).copy()\n    df_brutal_NA = df_brutal_NA.drop(labels=df_brutal_NA.loc[df_brutal_NA['Electrical'].isnull()].index)\nexcept:\n    print(\"col has been dropped\")\n    pass\n\nprint(\"缺失值:\",df_brutal_NA.isnull().sum().max()) #確認已無缺失值\nall_data_na = (df_brutal_NA.isnull().sum() / len(df_brutal_NA)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_col = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_col.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.064058Z","iopub.execute_input":"2021-11-27T05:55:13.064336Z","iopub.status.idle":"2021-11-27T05:55:13.096256Z","shell.execute_reply.started":"2021-11-27T05:55:13.064307Z","shell.execute_reply":"2021-11-27T05:55:13.095347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#逐一分析法\ndf_wise_NA = df.copy()\ndf_wise_NA[\"PoolQC\"] = df_wise_NA[\"PoolQC\"].fillna(\"None\")  #泳池，且該特徵為類別特徵 因此填None\ndf_wise_NA[\"MiscFeature\"] = df_wise_NA[\"MiscFeature\"].fillna(\"None\")  #額外設施 同上\ndf_wise_NA[\"Alley\"] = df_wise_NA[\"Alley\"].fillna(\"None\")  # 小道鋪面 同上\ndf_wise_NA[\"Fence\"] = df_wise_NA[\"Fence\"].fillna(\"None\")  #柵欄隱私度 同上\ndf_wise_NA[\"FireplaceQu\"] = df_wise_NA[\"FireplaceQu\"].fillna(\"None\")  #壁爐品質 同上\ndf_wise_NA[\"LotFrontage\"] = df_wise_NA.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))  #這就要小心了，該特徵為與房子相連的街道長，由於每個房子可能都差不多，因此Na填入中值\n\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):  #車庫相關的類別特徵 沒車庫的會是None\n    df_wise_NA[col] = df_wise_NA[col].fillna('None') \n\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):  #車庫相關的數值特徵 沒車庫的會是0\n    df_wise_NA[col] = df_wise_NA[col].fillna(0)  \n\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):  #地下室相關的類別特徵 沒有的會是None\n    df_wise_NA[col] = df_wise_NA[col].fillna('None')  \n\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):  #地下室相關的數值特徵 沒有的會是0\n    df_wise_NA[col] = df_wise_NA[col].fillna(0)\n    \ndf_wise_NA[\"MasVnrType\"] = df_wise_NA[\"MasVnrType\"].fillna(\"None\")  #房屋飾面種類 類別特徵，沒有的會是None\ndf_wise_NA[\"MasVnrArea\"] = df_wise_NA[\"MasVnrArea\"].fillna(0)  #房屋飾面面積 數值特徵，沒有的會是0\ndf_wise_NA['Electrical'] = df_wise_NA['Electrical'].fillna(df_wise_NA['Electrical'].mode()[0])    #關於電力系統 類別特徵 缺失值填為電力系統該有的功能:\"SBrkr\"\ndf_wise_NA['MSZoning'] = df_wise_NA['MSZoning'].fillna(df_wise_NA['MSZoning'].mode()[0])  #關於建地類別 類別特徵 填眾數\ndf_wise_NA = df_wise_NA.drop(['Utilities'], axis=1)  #該缺失值只在測試集出現，且在訓練集中大家都一樣(一例例外)，所以該特徵是冗於特徵，可去除\ndf_wise_NA[\"Functional\"] = df_wise_NA[\"Functional\"].fillna(\"Typ\")  #數據說明表示Na即為\"Typ\"\n\ndf_wise_NA['Exterior1st'] = df_wise_NA['Exterior1st'].fillna(df_wise_NA['Exterior1st'].mode()[0])  #外牆裝飾 類別特徵 填眾數\ndf_wise_NA['Exterior2nd'] = df_wise_NA['Exterior2nd'].fillna(df_wise_NA['Exterior2nd'].mode()[0])  #外牆裝飾 類別特徵 填眾數\ndf_wise_NA['KitchenQual'] = df_wise_NA['KitchenQual'].fillna(df_wise_NA['KitchenQual'].mode()[0])  #廚房品質 類別特徵 填眾數\ndf_wise_NA['SaleType'] = df_wise_NA['SaleType'].fillna(df_wise_NA['SaleType'].mode()[0])  #出售類別 類別特徵 填眾數\n\n#最後確認還有沒有遺失值\nprint(\"缺失值:\",df_wise_NA.isnull().sum().max()) #確認已無缺失值\nall_data_na = (df_wise_NA.isnull().sum() / len(df_wise_NA)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_col = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_col.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.098046Z","iopub.execute_input":"2021-11-27T05:55:13.098407Z","iopub.status.idle":"2021-11-27T05:55:13.172358Z","shell.execute_reply.started":"2021-11-27T05:55:13.098366Z","shell.execute_reply":"2021-11-27T05:55:13.17139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Featrue Encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n\ncols = df_wise_NA.select_dtypes(include='object').columns\n\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(df_wise_NA[c].values)) \n    df_wise_NA[c] = lbl.transform(list(df_wise_NA[c].values))\n\nprint('Shape all_data: {}'.format(df_wise_NA.shape))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.173764Z","iopub.execute_input":"2021-11-27T05:55:13.174407Z","iopub.status.idle":"2021-11-27T05:55:13.280698Z","shell.execute_reply.started":"2021-11-27T05:55:13.17436Z","shell.execute_reply":"2021-11-27T05:55:13.27981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"由於房價和坪數相關，因此新增一個特徵:面積總和","metadata":{"execution":{"iopub.status.busy":"2021-10-30T07:10:02.59642Z","iopub.execute_input":"2021-10-30T07:10:02.596727Z","iopub.status.idle":"2021-10-30T07:10:02.602032Z","shell.execute_reply.started":"2021-10-30T07:10:02.596693Z","shell.execute_reply":"2021-10-30T07:10:02.601157Z"}}},{"cell_type":"code","source":"df_wise_NA['TotalSF'] = df_wise_NA['TotalBsmtSF'] + df_wise_NA['1stFlrSF'] + df_wise_NA['2ndFlrSF']","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.282044Z","iopub.execute_input":"2021-11-27T05:55:13.282896Z","iopub.status.idle":"2021-11-27T05:55:13.290114Z","shell.execute_reply.started":"2021-11-27T05:55:13.282849Z","shell.execute_reply":"2021-11-27T05:55:13.289197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"處理特徵的偏度","metadata":{}},{"cell_type":"markdown","source":"利用Box Cox轉換","metadata":{}},{"cell_type":"code","source":"def fix_skew(df, ntrain, shew=0.75, lamda = 0.15):\n    from scipy.stats import norm, skew\n    from scipy.special import boxcox1p\n    \n    numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n    skewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n    print(\"\\n Skew in numerical features: \\n\")\n    skewness = pd.DataFrame({'Skew' :skewed_feats})\n    print(skewness.head(10).T)\n    \n    skewness = skewness[abs(skewness['Skew'])>shew]\n    print(\"\\n There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n    \n    skewed_features = skewness.index\n    \n    for feat in skewed_features:\n        df[feat] = boxcox1p(df[feat], lamda)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.291417Z","iopub.execute_input":"2021-11-27T05:55:13.291724Z","iopub.status.idle":"2021-11-27T05:55:13.305364Z","shell.execute_reply.started":"2021-11-27T05:55:13.291685Z","shell.execute_reply":"2021-11-27T05:55:13.304005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fix_skew(df_wise_NA, ntrain, shew=0.75, lamda = 0.15)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.306558Z","iopub.execute_input":"2021-11-27T05:55:13.306823Z","iopub.status.idle":"2021-11-27T05:55:13.442547Z","shell.execute_reply.started":"2021-11-27T05:55:13.306757Z","shell.execute_reply":"2021-11-27T05:55:13.441325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#類別轉one-hot\ndf_wise_NA = pd.get_dummies(df_wise_NA)\nprint(df_wise_NA.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:29:03.711045Z","iopub.execute_input":"2021-11-27T06:29:03.711407Z","iopub.status.idle":"2021-11-27T06:29:03.726746Z","shell.execute_reply.started":"2021-11-27T06:29:03.711368Z","shell.execute_reply":"2021-11-27T06:29:03.725888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_wise_NA[:ntrain]\ntest = df_wise_NA[ntrain:]","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.459758Z","iopub.execute_input":"2021-11-27T05:55:13.460031Z","iopub.status.idle":"2021-11-27T05:55:13.465873Z","shell.execute_reply.started":"2021-11-27T05:55:13.460002Z","shell.execute_reply":"2021-11-27T05:55:13.464843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 建模","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:13.467796Z","iopub.execute_input":"2021-11-27T05:55:13.468155Z","iopub.status.idle":"2021-11-27T05:55:14.719996Z","shell.execute_reply.started":"2021-11-27T05:55:13.468111Z","shell.execute_reply":"2021-11-27T05:55:14.719077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"基礎模型","metadata":{}},{"cell_type":"code","source":"def rmsle_cv(X, y, model, n_folds=5):\n        kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X.values)\n        rmse= np.sqrt(-cross_val_score(model, X.values, y, scoring=\"neg_mean_squared_error\", cv = kf))\n        return(rmse)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:14.721333Z","iopub.execute_input":"2021-11-27T05:55:14.721638Z","iopub.status.idle":"2021-11-27T05:55:14.728865Z","shell.execute_reply.started":"2021-11-27T05:55:14.721607Z","shell.execute_reply":"2021-11-27T05:55:14.727841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simple_model_test(X, y ,n_folds = 5):\n    \n    lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n    ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n    Svr = make_pipeline(RobustScaler(), SVR(kernel='linear', degree=3, C=0.5, epsilon=0.1))\n    KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n    \n    rf = RandomForestRegressor(n_estimators=1200, max_depth=15, min_samples_split=5,\n                          min_samples_leaf=5, max_features=None, oob_score=True, random_state=42)\n\n    GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =5)\n    \n    VotingR = VotingRegressor(estimators=[('ls', lasso), ('EN', ENet), ('Svr', Svr), ('kr', KRR), ('rf', rf), ('gb', GBoost)])\n    \n    \n    model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3, min_child_weight=1.7817, n_estimators=2200,\n                                 reg_alpha=0.4640, reg_lambda=0.8571, subsample=0.5213, random_state =7, nthread = -1)\n    model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5, learning_rate=0.05, n_estimators=720,\n                                  max_bin = 55, feature_fraction_seed=9, bagging_seed=9)\n    \n    model_list = {'VR':VotingR, 'XGB':model_xgb, 'LGBM':model_lgb}\n    \n    for n,m in model_list.items():\n        score = rmsle_cv(X, y, m, n_folds)\n        print('\\n{} score: {:.4f} ({:.4f})\\n'.format(n, score.mean(), score.std()))\n    return VotingR, model_xgb, model_lgb","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:14.730357Z","iopub.execute_input":"2021-11-27T05:55:14.730835Z","iopub.status.idle":"2021-11-27T05:55:14.743746Z","shell.execute_reply.started":"2021-11-27T05:55:14.730632Z","shell.execute_reply":"2021-11-27T05:55:14.742919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    def fit(self, X, y):\n        self.models_ = [clone(m) for m in self.models]\n        \n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)   ","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:14.74513Z","iopub.execute_input":"2021-11-27T05:55:14.745769Z","iopub.status.idle":"2021-11-27T05:55:14.759451Z","shell.execute_reply.started":"2021-11-27T05:55:14.745732Z","shell.execute_reply":"2021-11-27T05:55:14.758509Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VotingR, model_xgb, model_lgb = simple_model_test(train, y_train ,n_folds = 5)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:55:14.763038Z","iopub.execute_input":"2021-11-27T05:55:14.763294Z","iopub.status.idle":"2021-11-27T05:57:50.571803Z","shell.execute_reply.started":"2021-11-27T05:55:14.763265Z","shell.execute_reply":"2021-11-27T05:57:50.571114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"averaged_models = AveragingModels(models = (VotingR, model_xgb, model_lgb))\n\nscore = rmsle_cv(train, y_train, averaged_models, n_folds = 5)\nprint(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:57:50.573257Z","iopub.execute_input":"2021-11-27T05:57:50.574027Z","iopub.status.idle":"2021-11-27T06:00:24.72584Z","shell.execute_reply.started":"2021-11-27T05:57:50.573979Z","shell.execute_reply":"2021-11-27T06:00:24.724551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"法2. 增加meta-model\n在這個方法中，基於基礎模型堆疊上，額外增加了一個meta-model，再利用這些基本模型的外插驗證預測(holdout)去訓練meta-model。","metadata":{}},{"cell_type":"code","source":"class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    # we define clones of the original models to fit the data in\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)   ","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:02:39.75677Z","iopub.execute_input":"2021-11-27T06:02:39.757132Z","iopub.status.idle":"2021-11-27T06:02:39.764807Z","shell.execute_reply.started":"2021-11-27T06:02:39.757095Z","shell.execute_reply":"2021-11-27T06:02:39.763693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_averaged_models = StackingAveragedModels(models = (VotingR, model_xgb, model_lgb))\n\nscore = rmsle_cv(train, y_train, averaged_models, n_folds = 5)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:03:14.173266Z","iopub.execute_input":"2021-11-27T06:03:14.173972Z","iopub.status.idle":"2021-11-27T06:05:48.833449Z","shell.execute_reply.started":"2021-11-27T06:03:14.173919Z","shell.execute_reply":"2021-11-27T06:05:48.83247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensembling","metadata":{}},{"cell_type":"code","source":"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:05:48.83527Z","iopub.execute_input":"2021-11-27T06:05:48.835505Z","iopub.status.idle":"2021-11-27T06:05:48.840247Z","shell.execute_reply.started":"2021-11-27T06:05:48.835477Z","shell.execute_reply":"2021-11-27T06:05:48.839065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# StackedRegressor\nstacked_averaged_models.fit(train.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(train.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\nprint(rmsle(y_train, stacked_train_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:05:48.841724Z","iopub.execute_input":"2021-11-27T06:05:48.841985Z","iopub.status.idle":"2021-11-27T06:06:27.36896Z","shell.execute_reply.started":"2021-11-27T06:05:48.841956Z","shell.execute_reply":"2021-11-27T06:06:27.368263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XGBoost\nmodel_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:06:27.370793Z","iopub.execute_input":"2021-11-27T06:06:27.371461Z","iopub.status.idle":"2021-11-27T06:06:30.848028Z","shell.execute_reply.started":"2021-11-27T06:06:27.371423Z","shell.execute_reply":"2021-11-27T06:06:30.847251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LightGBM\nmodel_lgb.fit(train, y_train)\nlgb_train_pred = model_lgb.predict(train)\nlgb_pred = np.expm1(model_lgb.predict(test.values))\nprint(rmsle(y_train, lgb_train_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:06:30.849223Z","iopub.execute_input":"2021-11-27T06:06:30.850191Z","iopub.status.idle":"2021-11-27T06:06:31.126915Z","shell.execute_reply.started":"2021-11-27T06:06:30.850142Z","shell.execute_reply":"2021-11-27T06:06:31.12614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('RMSLE score on train data:')\ntrain_pred = stacked_train_pred*0.6 + xgb_train_pred*0.2 + lgb_train_pred*0.2\nprint(rmsle(y_train, train_pred))\nprint('平均誤差:', (np.expm1(train_pred)-np.expm1(y_train)).mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:06:31.128081Z","iopub.execute_input":"2021-11-27T06:06:31.128569Z","iopub.status.idle":"2021-11-27T06:06:31.136667Z","shell.execute_reply.started":"2021-11-27T06:06:31.128536Z","shell.execute_reply":"2021-11-27T06:06:31.13531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = 0\nprint('真實值: {}, 預測值: {}'.format(np.expm1(y_train[sample]), np.expm1(train_pred[sample])))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:06:31.138228Z","iopub.execute_input":"2021-11-27T06:06:31.138497Z","iopub.status.idle":"2021-11-27T06:06:31.153721Z","shell.execute_reply.started":"2021-11-27T06:06:31.138468Z","shell.execute_reply":"2021-11-27T06:06:31.15272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ensemble prediction:\nensemble = lgb_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:06:31.155357Z","iopub.execute_input":"2021-11-27T06:06:31.156057Z","iopub.status.idle":"2021-11-27T06:06:31.165803Z","shell.execute_reply.started":"2021-11-27T06:06:31.15601Z","shell.execute_reply":"2021-11-27T06:06:31.164972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Submission\nsub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = ensemble\nsub.to_csv('submission.csv',index=False)\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2021-11-27T06:06:31.169529Z","iopub.execute_input":"2021-11-27T06:06:31.170325Z","iopub.status.idle":"2021-11-27T06:06:31.191746Z","shell.execute_reply.started":"2021-11-27T06:06:31.170275Z","shell.execute_reply":"2021-11-27T06:06:31.191017Z"},"trusted":true},"execution_count":null,"outputs":[]}]}